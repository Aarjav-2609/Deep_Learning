{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PeaGuClf6f3"
      },
      "source": [
        "# Reconstructing MNIST images using Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xx6GUcllf6f6"
      },
      "source": [
        "Now that we have understood how autoencoders reconstruct the inputs, in this section we will learn how autoencoders reconstruct the images of handwritten digits using the MNIST dataset.\n",
        "\n",
        "\n",
        "In this chapter, we use keras API from the tensorflow for building the models. So that we would be familiarized with how to use high-level APIs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bikY4Y-Af6f6"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfBDVeq4f6f6"
      },
      "source": [
        "First, let us import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "G_SKwRiof6f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "736b081d-9ab4-4ea2-c780-effae37bf77a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "import tensorflow.compat.v1 as tf; tf.disable_v2_behavior()\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "#plotting\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#dataset\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsnqPUsaf6f8"
      },
      "source": [
        "## Prepare the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2x9qM2df6f8"
      },
      "source": [
        "Let us load the MNIST dataset. We don't need the labels for autoencoder. Since we are reconstructing the given input we don't need the labels. So, we just load x_train for training and x_test for testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Zwhwvfmf6f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4208ffa7-9187-4578-8429-568d09bfd326"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upu6H3_lf6f9"
      },
      "source": [
        "Normalize the data by dividing with max pixel value which is 255:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuIbVAp3f6f9"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC41B_tif6f9"
      },
      "source": [
        "Shape of our dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDAaXxmlf6f9",
        "outputId": "a6ef779a-a957-41ba-b2ac-9392563a9382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLO3RhJef6f-"
      },
      "source": [
        "Reshape the images as 2D array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0VBSenWf6f-"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMZuR811f6f-"
      },
      "source": [
        "Now, the shape of data would become:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LF1egZFef6f_",
        "outputId": "728051fe-b499-4ea8-fb18-dcbbe633c7b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (10000, 784)\n"
          ]
        }
      ],
      "source": [
        "print(x_train.shape, x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4QmVCb7f6f_"
      },
      "source": [
        "# Define the Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYVCCFHCf6f_"
      },
      "source": [
        "Now, we define the encoder which takes the images as an input and returns the encodings.\n",
        "\n",
        "Define the size of the encodings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wgt4Wb2f6f_"
      },
      "outputs": [],
      "source": [
        "encoding_dim = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI_msn52f6gA"
      },
      "source": [
        "Define the placeholders for the input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulPaSP-vf6gA"
      },
      "outputs": [],
      "source": [
        "input_image = Input(shape=(784,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jj9Ya1Pgf6gA"
      },
      "source": [
        "\n",
        "Define the encoder which takes the input_image and returns the encodings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7s5m9Luf6gA"
      },
      "outputs": [],
      "source": [
        "encoder  = Dense(encoding_dim, activation='relu')(input_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BAzYYzcf6gA"
      },
      "source": [
        "# Define the Decoder\n",
        "\n",
        "Let us define the decoder which takes the encoded values from the encoder and returns the reconstructed image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQBDZ2Epf6gB"
      },
      "outputs": [],
      "source": [
        "decoder = Dense(784, activation='sigmoid')(encoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qN0NTvBRf6gB"
      },
      "source": [
        "# Build the model\n",
        "\n",
        "Now that we defined encoder and decoder, we define the model which takes images as input and returns the output of the decoder which is the reconstructed image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQSRKbaDf6gB"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs=input_image, outputs=decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v4Hfjcef6gB"
      },
      "source": [
        "Let us look at summary of the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMP-wRxvf6gB",
        "outputId": "4e3d6a4a-3772-4ab2-bcd2-6fd91c036914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                25120     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 784)               25872     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,992\n",
            "Trainable params: 50,992\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6RifqXsf6gC"
      },
      "source": [
        "Compile the model with loss as binary cross entropy and we minimize the loss using AdaDelta optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA7vvgTaf6gC"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7p_LALTdf6gC"
      },
      "source": [
        "Now, let us train the model.\n",
        "\n",
        "Generally, we feed the data to the model as model.fit(x,y) where x is the input and y is the label. But since autoencoders reconstruct its inputs, the input and output to the model should be the same. So we feed the data to the model as model.fit(x_train, x_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Je6-JiHDf6gD",
        "outputId": "47a9c942-bbce-4193-b160-abde52a7729f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "60000/60000 [==============================] - 3s 56us/sample - loss: 0.2768 - val_loss: 0.1926\n",
            "Epoch 2/50\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.1731 - val_loss: 0.1553\n",
            "Epoch 3/50\n",
            "60000/60000 [==============================] - 5s 84us/sample - loss: 0.1456 - val_loss: 0.1346\n",
            "Epoch 4/50\n",
            "60000/60000 [==============================] - 5s 81us/sample - loss: 0.1294 - val_loss: 0.1224\n",
            "Epoch 5/50\n",
            "60000/60000 [==============================] - 4s 70us/sample - loss: 0.1192 - val_loss: 0.1137\n",
            "Epoch 6/50\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.1119 - val_loss: 0.1075\n",
            "Epoch 7/50\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.1065 - val_loss: 0.1031\n",
            "Epoch 8/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.1026 - val_loss: 0.0997\n",
            "Epoch 9/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0998 - val_loss: 0.0974\n",
            "Epoch 10/50\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0978 - val_loss: 0.0957\n",
            "Epoch 11/50\n",
            "60000/60000 [==============================] - 3s 56us/sample - loss: 0.0965 - val_loss: 0.0946\n",
            "Epoch 12/50\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0956 - val_loss: 0.0940\n",
            "Epoch 13/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0950 - val_loss: 0.0935\n",
            "Epoch 14/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0946 - val_loss: 0.0931\n",
            "Epoch 15/50\n",
            "60000/60000 [==============================] - 3s 53us/sample - loss: 0.0943 - val_loss: 0.0929\n",
            "Epoch 16/50\n",
            "60000/60000 [==============================] - 3s 52us/sample - loss: 0.0941 - val_loss: 0.0927\n",
            "Epoch 17/50\n",
            "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0939 - val_loss: 0.0925\n",
            "Epoch 18/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0938 - val_loss: 0.0925\n",
            "Epoch 19/50\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0937 - val_loss: 0.0924\n",
            "Epoch 20/50\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0936 - val_loss: 0.0923\n",
            "Epoch 21/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 22/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0934 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0933 - val_loss: 0.0921\n",
            "Epoch 24/50\n",
            "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 25/50\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0932 - val_loss: 0.0921\n",
            "Epoch 26/50\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0932 - val_loss: 0.0920\n",
            "Epoch 27/50\n",
            "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 28/50\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0931 - val_loss: 0.0920\n",
            "Epoch 29/50\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 30/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 31/50\n",
            "60000/60000 [==============================] - 2s 42us/sample - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 32/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 33/50\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 34/50\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 35/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 36/50\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 37/50\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 38/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 39/50\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 40/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 41/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 42/50\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 43/50\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 44/50\n",
            "60000/60000 [==============================] - 2s 40us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 45/50\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 46/50\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.0927 - val_loss: 0.0917\n",
            "Epoch 47/50\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 48/50\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 49/50\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 50/50\n",
            "60000/60000 [==============================] - 3s 50us/sample - loss: 0.0927 - val_loss: 0.0916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f69bd3c0190>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model.fit(x_train, x_train, epochs=50, batch_size=256, shuffle=True, validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bJm4ixcf6gD"
      },
      "source": [
        "## Reconstruct images\n",
        "\n",
        "Let us see how our model is performing in the test dataset. Feed the test images to the model and get the reconstructed images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_RTfj1Df6gE"
      },
      "outputs": [],
      "source": [
        "reconstructed_images = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqbk_geVf6gE"
      },
      "source": [
        "## Plotting reconstructed images\n",
        "\n",
        "\n",
        "First let us plot the atcual images i.e input images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "ACXjnGQ2f6gE",
        "outputId": "d5b097d3-d97b-44ef-8945-db45ea04e199"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "n = 7\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    ax = plt.subplot(1, n, i+1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-FVFNbcf6gF"
      },
      "source": [
        "Plot the reconstructed image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "qAKcU89uf6gF",
        "outputId": "bd15c63c-02d5-4502-ff97-8affebaef446"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x400 with 7 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "n = 7\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "    ax = plt.subplot(2, n, i + n + 1)\n",
        "    plt.imshow(reconstructed_images[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO5cNmxpf6gF"
      },
      "source": [
        "As you can notice, autoencoders have learned to reconstruct the given input image. In the next section, we will learn about convolutional autoencoder which uses convolutional layers in the encoder and decoder network."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}