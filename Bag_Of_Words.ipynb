{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcZertnJWIUt"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example texts\n",
        "texts = [\"This is the first document.\",\n",
        "         \"This document is the second document.\",\n",
        "         \"And this is the third one.\",\n",
        "         \"Is this the first document?\"]"
      ],
      "metadata": {
        "id": "yVrpz1g_WdHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-words using the Count Vectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_count = count_vectorizer.fit_transform(texts)\n",
        "bow_count_names = count_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "gft-GMg6WfVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-n-grams using the Count Vectorizer\n",
        "count_vectorizer_ngrams = CountVectorizer(ngram_range=(2,2))\n",
        "bow_count_ngrams = count_vectorizer_ngrams.fit_transform(texts)\n",
        "bow_count_ngrams_names = count_vectorizer_ngrams.get_feature_names_out()"
      ],
      "metadata": {
        "id": "BQisUNY1Whr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bag-of-words using the Tf-Idf Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "bow_tfidf = tfidf_vectorizer.fit_transform(texts)\n",
        "bow_tfidf_names = tfidf_vectorizer.get_feature_names_out()"
      ],
      "metadata": {
        "id": "jXK7tK6iWj21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output\n",
        "print(\"Bag-of-words using the Count Vectorizer:\\n\", bow_count.toarray(), \"\\n\")\n",
        "print(\"Feature names for Bag-of-words using the Count Vectorizer:\\n\", bow_count_names, \"\\n\")\n",
        "print(\"Bag-of-n-grams using the Count Vectorizer:\\n\", bow_count_ngrams.toarray(), \"\\n\")\n",
        "print(\"Feature names for Bag-of-n-grams using the Count Vectorizer:\\n\", bow_count_ngrams_names, \"\\n\")\n",
        "print(\"Bag-of-words using the Tf-Idf Vectorizer:\\n\", bow_tfidf.toarray(), \"\\n\")\n",
        "print(\"Feature names for Bag-of-words using the Tf-Idf Vectorizer:\\n\", bow_tfidf_names, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuYc5dBjXBuq",
        "outputId": "c027c0b1-8e98-4e7c-ddd9-d3e12813b78e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bag-of-words using the Count Vectorizer:\n",
            " [[0 1 1 1 0 0 1 0 1]\n",
            " [0 2 0 1 0 1 1 0 1]\n",
            " [1 0 0 1 1 0 1 1 1]\n",
            " [0 1 1 1 0 0 1 0 1]] \n",
            "\n",
            "Feature names for Bag-of-words using the Count Vectorizer:\n",
            " ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this'] \n",
            "\n",
            "Bag-of-n-grams using the Count Vectorizer:\n",
            " [[0 0 1 1 0 0 1 0 0 0 0 1 0]\n",
            " [0 1 0 1 0 1 0 1 0 0 1 0 0]\n",
            " [1 0 0 1 0 0 0 0 1 1 0 1 0]\n",
            " [0 0 1 0 1 0 1 0 0 0 0 0 1]] \n",
            "\n",
            "Feature names for Bag-of-n-grams using the Count Vectorizer:\n",
            " ['and this' 'document is' 'first document' 'is the' 'is this'\n",
            " 'second document' 'the first' 'the second' 'the third' 'third one'\n",
            " 'this document' 'this is' 'this the'] \n",
            "\n",
            "Bag-of-words using the Tf-Idf Vectorizer:\n",
            " [[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]\n",
            " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
            "  0.28108867 0.         0.28108867]\n",
            " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
            "  0.26710379 0.51184851 0.26710379]\n",
            " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
            "  0.38408524 0.         0.38408524]] \n",
            "\n",
            "Feature names for Bag-of-words using the Tf-Idf Vectorizer:\n",
            " ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CtT3jlApXGSR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}